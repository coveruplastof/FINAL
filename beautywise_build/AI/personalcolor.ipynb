{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1GIiGg_GXA4"
      },
      "outputs": [],
      "source": [
        "!pip install chromadb tiktoken transformers sentence_transformers openai langchain pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = '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'"
      ],
      "metadata": {
        "id": "8c1VKvOqGkHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "#tiktoken 라이브러리를 가져와서 선언, tokenizer를 기준으로 token을 세는 함수\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "\n",
        "def tiktoken_len(text):\n",
        "    tokens = tokenizer.encode(text)\n",
        "    return len(tokens)"
      ],
      "metadata": {
        "id": "-oFHWK-KG7Yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.document_loaders import WebBaseLoader"
      ],
      "metadata": {
        "id": "sI2nWqT3IEfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = WebBaseLoader([\"https://blog.naver.com/0108383/223049846109\", \"https://mycolor.kr/explain\", \"https://post.naver.com/viewer/postView.naver?volumeNo=29750016&memberNo=34537918\"])\n",
        "docs = loader.load()\n",
        "# 페이지별로 자르고 리스트를 pages에 저장\n",
        "pages = loader.load_and_split()\n",
        "\n",
        "# #불러온 텍스트를 청킹(recursive~를 통해), 위에 사용한 cl100k기반으로 토큰수를 셈\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50, length_function= tiktoken_len)\n",
        "\n",
        "texts = text_splitter.split_documents(pages) #pages -> document 객체\n",
        "# #texts는 위의 매개변수들(chunk size etc)에 맞게 청킹이 된 document 객체들의 list\n",
        "\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "model_name = \"jhgan/ko-sbert-nli\" # 한글 임베딩 모델\n",
        "model_kwargs = {'device': 'cpu'}\n",
        "encode_kwargs = {'normalize_embeddings': True}\n",
        "\n",
        "hf = HuggingFaceEmbeddings(\n",
        "  model_name=model_name,\n",
        "  model_kwargs=model_kwargs,\n",
        "  encode_kwargs=encode_kwargs\n",
        ")\n",
        "\n",
        "#크로마 벡터스토어에 저장\n",
        "docsearch = Chroma.from_documents(texts, hf)\n"
      ],
      "metadata": {
        "id": "ar6Jy38xHV9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "\n",
        "openai = ChatOpenAI(model_name=\"gpt-3.5-turbo\",\n",
        "                    #streaming=True, callbacks=[StreamingStdOutCallbackHandler()],\n",
        "                    #streaming -> 타이핑하는 것처럼 출력됨\n",
        "                    temperature = 0)\n",
        "                    #temperature -> 0부터 2 사이의 값, 낮을수록 일관된 답변을 하게 만들 수 있음\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(llm = openai,                               #llm은 openai, chain_type은 stuff\n",
        "                                 chain_type = \"stuff\",      # chunk size 500으로 작게 설정했으므로 여러 문서를 참고하더라도 토큰이 별로 소비가 안 됨, 질문과 컨텍스트 청크 500을 합쳐도\n",
        "                                                            # gpt 3.5의 4000을 절대 넘지 않을 것임. 청킹을 크게 하고 질문을 길게 한다 -> map reduce로 진행해도 됨\n",
        "                                 retriever = docsearch.as_retriever(\n",
        "                                    # 위에서 선언한대로 docsearch를 as_retriever로 검색기로 만들어 줄 것임, chroma를 벡터 저장소가 아니라 연관성 높은걸 찾는 검색기로 쓸 것임.\n",
        "                                    search_type=\"mmr\",                      # mmr을 설정하면 연관성 높은 문서를 뽑아올 때 풀 중에서 최대한 다양하게 컨텍스트를 조합할 수 있게 함\n",
        "                                    search_kwargs={'k':3, 'fetch_k':6}),    # fetch_k는 위의 후보군의 총 갯수, k는 그 중에서 넘겨줄 갯수\n",
        "                                 #return_source_documents=True              # 질문한거에 답변할 때 llm이 참고한 컨텍스트가 어디에 있었던 문서인지 소스를 알 수 있게끔 해주는 부분\n",
        "                                 )\n",
        "query = \"봄 브라이트\"+'에 어울리는 스타일링 추천해줘'\n",
        "\n",
        "result=qa(query)\n",
        "\n",
        "text = result['result']\n"
      ],
      "metadata": {
        "id": "hm5SaqcDu5NX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "\n",
        "openai = ChatOpenAI(model_name=\"gpt-3.5-turbo\",\n",
        "                    #streaming=True, callbacks=[StreamingStdOutCallbackHandler()],\n",
        "                    #streaming -> 타이핑하는 것처럼 출력됨\n",
        "                    temperature = 0)\n",
        "                    #temperature -> 0부터 2 사이의 값, 낮을수록 일관된 답변을 하게 만들 수 있음\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(llm = openai,                               #llm은 openai, chain_type은 stuff\n",
        "                                 chain_type = \"stuff\",      # chunk size 500으로 작게 설정했으므로 여러 문서를 참고하더라도 토큰이 별로 소비가 안 됨, 질문과 컨텍스트 청크 500을 합쳐도\n",
        "                                                            # gpt 3.5의 4000을 절대 넘지 않을 것임. 청킹을 크게 하고 질문을 길게 한다 -> map reduce로 진행해도 됨\n",
        "                                 retriever = docsearch.as_retriever(\n",
        "                                    # 위에서 선언한대로 docsearch를 as_retriever로 검색기로 만들어 줄 것임, chroma를 벡터 저장소가 아니라 연관성 높은걸 찾는 검색기로 쓸 것임.\n",
        "                                    search_type=\"mmr\",                      # mmr을 설정하면 연관성 높은 문서를 뽑아올 때 풀 중에서 최대한 다양하게 컨텍스트를 조합할 수 있게 함\n",
        "                                    search_kwargs={'k':3, 'fetch_k':6}),    # fetch_k는 위의 후보군의 총 갯수, k는 그 중에서 넘겨줄 갯수\n",
        "                                 #return_source_documents=True              # 질문한거에 답변할 때 llm이 참고한 컨텍스트가 어디에 있었던 문서인지 소스를 알 수 있게끔 해주는 부분\n",
        "                                 )\n",
        "query = \"가을 딥\"+'에 어울리는 스타일링 추천해줘'\n",
        "\n",
        "result=qa(query)\n",
        "\n",
        "text = result['result']"
      ],
      "metadata": {
        "id": "MpQNfbX5D7QA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "eUTxWv8QE3dS",
        "outputId": "277064b9-2922-45c0-e4aa-de0c199c49a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'가을 딥 톤에 어울리는 스타일링을 추천해드릴게요. 가을 딥 톤은 어두운 음영이 있는 색상과 섹시한 매력이 특징이에요. 따라서 다음과 같은 스타일링이 잘 어울릴 수 있어요:\\n\\n1. 어두운 컬러의 의상: 가을 딥 톤에 어울리는 어두운 컬러의 의상을 선택해보세요. 예를 들어, 검정, 짙은 갈색, 어두운 그린 등이 좋은 선택일 수 있어요.\\n\\n2. 섹시한 실루엣: 가을 딥 톤은 섹시한 매력을 지니고 있으므로, 실루엣이 섹시하고 여리여리한 의상을 선택해보세요. 예를 들어, 플레어 스커트, 허리를 강조하는 드레스 등이 좋은 선택일 수 있어요.\\n\\n3. 은은한 메이크업: 가을 딥 톤에 어울리는 은은한 메이크업을 해보세요. 예를 들어, 브라운 계열의 아이섀도우와 립스틱을 사용하면 자연스럽고 세련된 느낌을 줄 수 있어요.\\n\\n4. 악세서리 선택: 가을 딥 톤에 어울리는 악세서리를 선택해보세요. 예를 들어, 골드나 은색 악세서리가 가을 딥 톤과 잘 어울릴 수 있어요.\\n\\n이런 스타일링을 참고하시면 가을 딥 톤의 매력을 더욱 돋보일 수 있을 거예요.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 생성된 정보를 이미지 AI에 스크립팅하기 위해 단어를 중점으로 변환\n",
        "\n",
        "def transform_to_script(text):\n",
        "    # 여기에서는 단어 단위로 분할한 후, 각 단어를 조합하여 스크립트 형식으로 반환합니다.\n",
        "    words = text.split()  # 단어 단위로 분할\n",
        "    script = \" \".join(words)  # 단어를 공백으로 조합\n",
        "    return script\n",
        "\n",
        "# 생성된 정보를 이미지 AI에 스크립팅하기 위해 단어 단위로 중점을 두어 변환\n",
        "\n",
        "response_text_script = transform_to_script(text)\n",
        "response_text_script\n",
        "# 이제 response_text_script를 사용하여 이미지 AI에 스크립팅하거나 다른 필요한 작업을 수행할 수 있습니다.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "fpvgHnyV2L7Q",
        "outputId": "c0a24e1b-f312-4e40-cafc-8795ae13e148"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'봄 브라이트에 어울리는 스타일링을 추천해드릴게요! 봄 브라이트는 고명도의 밝고 쨍한 컬러가 어울리는 톤이기 때문에 화사하고 발랄한 느낌을 연출할 수 있어요. 아래는 몇 가지 스타일링 아이디어입니다: 1. 파스텔톤 드레스: 봄 브라이트에 어울리는 파스텔톤의 드레스를 선택해보세요. 예를 들어 연한 핑크나 민트색의 드레스는 봄 브라이트의 밝은 피부톤과 잘 어울리며 청순하고 여성스러운 느낌을 줄 수 있어요. 2. 화사한 패턴 스커트: 봄 브라이트에는 화사하고 다채로운 패턴의 스커트가 잘 어울립니다. 꽃이나 동물 프린트 등 다양한 패턴을 선택해보세요. 이렇게 화사한 스커트를 입으면 봄의 정열과 활기를 느낄 수 있어요. 3. 밝은 컬러의 상의와 바지: 봄 브라이트에는 밝은 컬러의 상의와 바지를 조합해보세요. 예를 들어 연한 노란색의 상의와 밝은 블루 컬러의 바지를 입으면 상큼하고 화사한 봄 브라이트의 이미지를 연출할 수 있어요. 4. 액세서리 강조: 봄 브라이트에는 액세서리를 활용하여 포인트를 줄 수 있어요. 예를 들어 화사한 컬러의 스카프, 큰 귀걸이, 컬러풀한 팔찌 등을 활용해보세요. 액세서리를 통해 봄 브라이트의 화사한 느낌을 더욱 강조할 수 있어요. 이런 스타일링 아이디어를 참고하시면 봄 브라이트의 퍼스널컬러를 더욱 돋보이게 연출할 수 있을 거예요. 즐거운 스타일링 되세요!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    }
  ]
}